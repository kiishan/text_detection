{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV Text Detection (EAST text detector)\n",
    "\n",
    "As we’ll learn, OpenCV’s text detector implementation of EAST is quite robust, capable of localizing text even when it’s blurred, reflective, or partially obscured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions(scores, geometry):\n",
    "    # grab the number of rows and columns from the scores volume, then\n",
    "    # initialize our set of bounding box rectangles and corresponding\n",
    "    # confidence scores\n",
    "    (numRows, numCols) = scores.shape[2:4]\n",
    "    rects = []\n",
    "    confidences = []\n",
    " \n",
    "    # loop over the number of rows\n",
    "    for y in range(0, numRows):\n",
    "        # extract the scores (probabilities), followed by the\n",
    "        # geometrical data used to derive potential bounding box\n",
    "        # coordinates that surround text\n",
    "        scoresData = scores[0, 0, y]\n",
    "        xData0 = geometry[0, 0, y]\n",
    "        xData1 = geometry[0, 1, y]\n",
    "        xData2 = geometry[0, 2, y]\n",
    "        xData3 = geometry[0, 3, y]\n",
    "        anglesData = geometry[0, 4, y]\n",
    " \n",
    "        # loop over the number of columns\n",
    "        for x in range(0, numCols):\n",
    "            # if our score does not have sufficient probability,\n",
    "            # ignore it\n",
    "            if scoresData[x] < min_confidence:\n",
    "                continue\n",
    " \n",
    "            # compute the offset factor as our resulting feature\n",
    "            # maps will be 4x smaller than the input image\n",
    "            (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    " \n",
    "            # extract the rotation angle for the prediction and\n",
    "            # then compute the sin and cosine\n",
    "            angle = anglesData[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    " \n",
    "            # use the geometry volume to derive the width and height\n",
    "            # of the bounding box\n",
    "            h = xData0[x] + xData2[x]\n",
    "            w = xData1[x] + xData3[x]\n",
    " \n",
    "            # compute both the starting and ending (x, y)-coordinates\n",
    "            # for the text prediction bounding box\n",
    "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    " \n",
    "            # add the bounding box coordinates and probability score\n",
    "            # to our respective lists\n",
    "            rects.append((startX, startY, endX, endY))\n",
    "            confidences.append(scoresData[x])\n",
    " \n",
    "    # return a tuple of the bounding boxes and associated confidences\n",
    "    return (rects, confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = '12.mp4'\n",
    "east = 'frozen_east_text_detection.pb'\n",
    "min_confidence = 0.8\n",
    "width = 320\n",
    "height = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the original frame dimensions, new frame dimensions,\n",
    "# and ratio between the dimensions\n",
    "(W, H) = (None, None)\n",
    "(newW, newH) = (width, height)\n",
    "(rW, rH) = (None, None)\n",
    " \n",
    "# define the two output layer names for the EAST detector model that\n",
    "# we are interested -- the first is the output probabilities and the\n",
    "# second can be used to derive the bounding box coordinates of text\n",
    "layerNames = [\n",
    "    \"feature_fusion/Conv_7/Sigmoid\",\n",
    "    \"feature_fusion/concat_3\"]\n",
    " \n",
    "# load the pre-trained EAST text detector\n",
    "print(\"[INFO] loading EAST text detector...\")\n",
    "net = cv2.dnn.readNet(east)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = cv2.VideoCapture(video)\n",
    "\n",
    "# start the FPS throughput estimator\n",
    "fps = FPS().start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over frames from the video stream\n",
    "frame_count = 0\n",
    "while True:\n",
    "    text_boxes = 0\n",
    "    success,frame = vs.read()\n",
    "    frame_count += 1\n",
    "    # resize the frame, maintaining the aspect ratio\n",
    "    if frame is None:\n",
    "        break\n",
    "    \n",
    "    frame = imutils.resize(frame, width=1000)\n",
    "    orig = frame.copy()\n",
    "    print(orig.shape)\n",
    "    orig_x = orig.shape[1]//5\n",
    "    orig_y = orig.shape[0]//5\n",
    " \n",
    "    # if our frame dimensions are None, we still need to compute the\n",
    "    # ratio of old frame dimensions to new frame dimensions\n",
    "    if W is None or H is None:\n",
    "        (H, W) = frame.shape[:2]\n",
    "        rW = W / float(newW)\n",
    "        rH = H / float(newH)\n",
    " \n",
    "    # resize the frame, this time ignoring aspect ratio\n",
    "    frame = cv2.resize(frame, (newW, newH))\n",
    "    \n",
    "    \n",
    "    # construct a blob from the frame and then perform a forward pass\n",
    "    # of the model to obtain the two output layer sets\n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (newW, newH),\n",
    "        (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    (scores, geometry) = net.forward(layerNames)\n",
    " \n",
    "    # decode the predictions, then  apply non-maxima suppression to\n",
    "    # suppress weak, overlapping bounding boxes\n",
    "    (rects, confidences) = decode_predictions(scores, geometry)\n",
    "    boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "    \n",
    "    \n",
    "    # loop over the bounding boxes\n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "        \n",
    "        # scale the bounding box coordinates based on the respective\n",
    "        # ratios\n",
    "        startX = int(startX * rW)\n",
    "        startY = int(startY * rH)\n",
    "        endX = int(endX * rW)\n",
    "        endY = int(endY * rH)\n",
    "         \n",
    "        if startX and endX in range(orig_x,orig_x*4) and startY and endY in range(orig_y,orig_y*4):\n",
    "        \n",
    "            # draw the bounding box on the frame\n",
    "            cv2.rectangle(orig, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "            cv2.rectangle(orig, (orig_x, orig_y), (orig_x*4, orig_y*4), (255, 255, 0), 2)\n",
    "            text_boxes += 1\n",
    "        \n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    # update the FPS counter\n",
    "    fps.update()\n",
    " \n",
    "    # show the output frame\n",
    "    cv2.imshow(\"Text Detection\", orig)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    " \n",
    "    print(frame_count,text_boxes)\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "    \n",
    " \n",
    "# stop the timer and display FPS information\n",
    "fps.stop()\n",
    "print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "\n",
    "\n",
    "vs.release()\n",
    " \n",
    "# close all windows\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ python text_detection_video.py --east frozen_east_text_detection.pb  \n",
    "[INFO] loading EAST text detector...  \n",
    "[INFO] starting video stream...  \n",
    "[INFO] elasped time: 59.76  \n",
    "[INFO] approx. FPS: 8.85  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
